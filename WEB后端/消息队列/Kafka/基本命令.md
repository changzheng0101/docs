# 基本命令

## 进入镜像

`docker exec -it kafka-container-name /bin/bash`

## 创建/消费

创建队列

`kafka-topics --create --topic orders --bootstrap-server broker:9092`

接收消息

`kafka-console-consumer --topic orders  --bootstrap-server broker:9092`

（之后消息会阻塞，添加`--from-beginning`才可以从头读取，否则不会读取到之间的message）

生产消息

`kafka-console-producer --topic orders  --bootstrap-server broker:9092`

producer

```bash
# 发送键值对，以:进行分割
kafka-console-producer \
  --topic orders \
  --bootstrap-server broker:9092 \
  --property parse.key=true \
  --property key.separator=":"
```

consumer

```bash
# 进行consume
kafka-console-consumer \
  --topic orders \
  --bootstrap-server broker:9092 \
  --from-beginning \
  --property print.key=true \
  --property key.separator="-"
```

>key.separator是用来分开key和value，consumer和producer的不用相同，默认情况键为null。

## 配置deserializer

如果出现了乱码，检查deserializer是否是对应的类型

```bash
kafka-console-consumer --topic example --bootstrap-server broker:9092 \
 --from-beginning \
 --property print.key=true \
 --property key.separator=" : " \
 --key-deserializer "org.apache.kafka.common.serialization.LongDeserializer" \
 --value-deserializer "org.apache.kafka.common.serialization.DoubleDeserializer"
```

## 配置partition 和 offset

创建有两个partition的topic。

`kafka-topics --create --topic example-topic --bootstrap-server broker:9092 --replication-factor 1 --partitions 2`

一个topic通常可有多个分区，record最终会进入哪个分区，取决于hash算法。并不会平均分配到对应的分区，数据的索引也是从后台开始的。

```bash
kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \
 --property print.key=true \
 --property key.separator="-" \
 --partition 1 \
 --offset 6
```

